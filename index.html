<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Speech Transcription</title>
  <style>
    pre {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
  </style>
</head>
<body>
    <h1>Speech to Text Transcription</h1>
    <p>Copy and paste the transcript into the textbox.  Periodically check to make sure that the app is still transcribing. If there is more than 15 seconds of silence it will go into a sleep mode. You have to click "Allow" again.</p>
    <textarea id="transcriptionCopy" rows = "10" cols = "50"></textarea>
<input id="ipAddress" value="192.168.1.195">Type IP address of server</input>
<button id="startButton">Start</button>
    <button id="stopButton" onclick = "initSpeechRecognition()">Stop</button>
<button onclick = "location.reload()">Restart</button>
 <button onclick="askOllamaSOAP()">Follow up  note SOAP</button>
 <button onclick="askOllamaSubj()">New consult Subjective</button>
 <button onclick="askOllamaPlan()">New consult Assessment/Plan</button>
 <button onclick="justAsk()">Just ask a question</button>
 
<label for="endpoint">Azure OpenAI Endpoint:</label>
                <input type="text" id="endpoint" value="https://scriber03.openai.azure.com/" placeholder="https://your-resource.openai.azure.com/" />
                <small>Should NOT include /openai/v1/</small>
            <div class="form-group">
                <label for="apiKey">API Key:</label>
                <input type="password" id="apiKey" value="BZpqKiGl32b4VZLk5eYqyEl4S8Bhbn51pFEaMKK5lB3p87lGvUdeJQQJ99BIACREanaXJ3w3AAABACOGJeZm" />
            </div>
            <div class="form-group">
                <label for="deploymentName">Deployment Name:</label>
                <input type="text" id="deploymentName" value="o3-mini" placeholder="o3-mini" />
</div>
  <pre id="response"></pre>

<div id="transcription"></div>
    
  <script>


    async function justAsk() {

            const endpoint = document.getElementById('endpoint').value.trim();
            const apiKey = document.getElementById('apiKey').value.trim();
            const deploymentName = document.getElementById('deploymentName').value.trim();

      //const promptA = document.getElementById('transcription').textContent;
      const promptA = document.getElementById('transcriptionCopy').value;

      const prompt = "The following is a request from the user.  You are a helpful assistant. " + promptA    
const ipA = document.getElementById('ipAddress').value
if (ipA.length <6) {
  document.getElementById('response').textContent = "invalid IP address";
}                const apiVersion = "2025-01-01-preview";
                const apiUrl = `${endpoint.replace(/\/$/, '')}/openai/deployments/${deploymentName}/chat/completions?api-version=${apiVersion}`;

const url = 'http://' + ipA + ':3000/api/chat'

try {
    const xhr = new XMLHttpRequest();
    xhr.open('POST', apiUrl);
    xhr.setRequestHeader('Content-Type', 'application/json');
    xhr.setRequestHeader('api-key', apiKey);
    
    xhr.onload = function() {
        if (xhr.status === 200) {
            const data = JSON.parse(xhr.responseText);
            let booboo = data.choices?.[0]?.message?.content
            let startIndex = booboo.indexOf("</think>")
            let endIndex = booboo.length
            let truncatedStr = booboo.substring(startIndex, endIndex)   
            document.getElementById('response').textContent = truncatedStr || "No response";
        } else {
            document.getElementById('response').textContent = `HTTP Error: ${xhr.status}`;
        }
    };
    
    xhr.onerror = function() {
        document.getElementById('response').textContent = 'XMLHttpRequest failed';
    };
    
    xhr.send(JSON.stringify({
        messages: [
            {
                role: "system",
                content: "You are an AI assistant. Answer the question that the user asked or task that they gave you."
            },
            {
                role: "user",
                content: prompt
            }
        ],
        max_completion_tokens: 100000
    }));
}
catch (error) {
    document.getElementById('response').textContent = `XHR Error: ${error.message}`;
}
    }


    async function askOllamaSOAP() {
            const endpoint = document.getElementById('endpoint').value.trim();
            const apiKey = document.getElementById('apiKey').value.trim();
            const deploymentName = document.getElementById('deploymentName').value.trim();

      //const promptA = document.getElementById('transcription').textContent;
      const promptA = document.getElementById('transcriptionCopy').value;

      const prompt = "The following is a conversation between a doctor and patient.  Speaker diarization is not done - so you need to infer when the doctor is speaking and when the patient is speaking.  You are a medical assistant to help me write notes. Use the medical SOAP note format only - Subjective, Objective, Assessment, Plan. Please write a summary of what was discussed during the conversation. If there is no specific physical examination done, leave the Objective part of the SOAP note as N/A. Here is the dialogue: " + promptA    
const ipA = document.getElementById('ipAddress').value
if (ipA.length <6) {
  document.getElementById('response').textContent = "invalid IP address";
}                const apiVersion = "2025-01-01-preview";
                const apiUrl = `${endpoint.replace(/\/$/, '')}/openai/deployments/${deploymentName}/chat/completions?api-version=${apiVersion}`;

const url = 'http://' + ipA + ':3000/api/chat'

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'api-key': apiKey
                    },
                    body: JSON.stringify({
                        messages: [
                            {
                                role: "system",
                                content: "You are an AI assistant that helps with medical documentation and scribing. Please process and format the medical notes provided, ensuring accuracy and proper medical terminology."
                            },
                            {
                                role: "user",
                                content: prompt
                            }
                        ],
                        max_completion_tokens: 100000
                    })
                });


      const data = await response.json();   
    let booboo = data.choices?.[0]?.message?.content
      let startIndex = booboo.indexOf("</think>")
      let endIndex = booboo.length
         	  
      let truncatedStr = booboo.substring(startIndex, endIndex)   
      //document.getElementById('response').textContent = data.choices?.[0]?.message?.content || "No response";
      document.getElementById('response').textContent = truncatedStr || "No response";

    }


async function askOllamaSubj(){

            const endpoint = document.getElementById('endpoint').value.trim();
            const apiKey = document.getElementById('apiKey').value.trim();
            const deploymentName = document.getElementById('deploymentName').value.trim();

      //const promptA = document.getElementById('transcription').textContent;
      const promptA = document.getElementById('transcriptionCopy').value;

      const prompt = "This is a conversation between a doctor and a patient. Speaker diarization is not done - so you need to infer when the doctor is speaking and when the patient is speaking. I am in the doctor in this dialogue.  Create a summary of the patient's presenting problems using third person past tense. Don't numerate the response. Format it as the Subjective component of a medical SOAP note.  Make sure you include details like dates or numbers that were mentioned. The key is in the details in this part of the note.  Here is the dialogue: " + promptA    
const ipA = document.getElementById('ipAddress').value
if (ipA.length <6) {
  document.getElementById('response').textContent = "invalid IP address";
}                const apiVersion = "2025-01-01-preview";
                const apiUrl = `${endpoint.replace(/\/$/, '')}/openai/deployments/${deploymentName}/chat/completions?api-version=${apiVersion}`;

const url = 'http://' + ipA + ':3000/api/chat'

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'api-key': apiKey
                    },
                    body: JSON.stringify({
                        messages: [
                            {
                                role: "system",
                                content: "You are an AI assistant that helps with medical documentation and scribing. Please process and format the medical notes provided, ensuring accuracy and proper medical terminology."
                            },
                            {
                                role: "user",
                                content: prompt
                            }
                        ],
                        max_completion_tokens: 100000
                    })
                });


      const data = await response.json();   
    let booboo = data.choices?.[0]?.message?.content
      let startIndex = booboo.indexOf("</think>")
      let endIndex = booboo.length
         	  
      let truncatedStr = booboo.substring(startIndex, endIndex)   
      //document.getElementById('response').textContent = data.choices?.[0]?.message?.content || "No response";
      document.getElementById('response').textContent = truncatedStr || "No response";


}

    async function askOllamaPlan() {

            const endpoint = document.getElementById('endpoint').value.trim();
            const apiKey = document.getElementById('apiKey').value.trim();
            const deploymentName = document.getElementById('deploymentName').value.trim();

      //const promptA = document.getElementById('transcription').textContent;
      const promptA = document.getElementById('transcriptionCopy').value;

      const prompt = "This is a conversation between a doctor and patient. Speaker diarization is not done - so you need to infer when the doctor is speaking and when the patient is speaking. I am the doctor in this dialogue. We are discussing an assessment and plan after examining the patient. Format it as the Assessment + Plan component of a medical SOAP note.  The Assessment part should be in prose with details about diagnosis or working plan. The Plan part should include any prescriptions I gave, follow up instructions, or any surgeries I have booked the patient for. The plan should be written as a list but don't use numbers to create the list. Refer to the patient in third person. Here is the dialogue: " + promptA    
const ipA = document.getElementById('ipAddress').value
if (ipA.length <6) {
  document.getElementById('response').textContent = "invalid IP address";
}                const apiVersion = "2025-01-01-preview";
                const apiUrl = `${endpoint.replace(/\/$/, '')}/openai/deployments/${deploymentName}/chat/completions?api-version=${apiVersion}`;

const url = 'http://' + ipA + ':3000/api/chat'

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    mode: 'cors',
                    headers: {
                        'Content-Type': 'application/json',
                        'api-key': apiKey
                    },
                    body: JSON.stringify({
                        messages: [
                            {
                                role: "system",
                                content: "You are an AI assistant that helps with medical documentation and scribing. Please process and format the medical notes provided, ensuring accuracy and proper medical terminology."
                            },
                            {
                                role: "user",
                                content: prompt
                            }
                        ],
                        max_completion_tokens: 100000
                    })
                });


      const data = await response.json();   
    let booboo = data.choices?.[0]?.message?.content
      let startIndex = booboo.indexOf("</think>")
      let endIndex = booboo.length
         	  
      let truncatedStr = booboo.substring(startIndex, endIndex)   
      //document.getElementById('response').textContent = data.choices?.[0]?.message?.content || "No response";
      document.getElementById('response').textContent = truncatedStr || "No response";

    }
</script>
<script>
        const transcriptionDiv = document.getElementById('transcription');
        let isDoctorSpeaking = false;
        let recognition;
const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');


        // Initialize Speech Recognition
        function initSpeechRecognition() {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = function(event) {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        transcript += event.results[i][0].transcript.trim() + '. ';
                    }
                }
                appendTranscript(transcript);
            };

            recognition.onerror = function(event) {
                console.error('Speech recognition error detected: ' + event.error);
            };

            recognition.onend = function() {
                // Restart recognition after it ends
                recognition.start();
            };

            recognition.start();

        // Event listeners for mouse press and release
        //document.addEventListener('click', () => {
          //  isDoctorSpeaking = !isDoctorSpeaking;
            //console.log(`Speaker toggled: ${isDoctorSpeaking ? 'Doctor' : 'Patient'}`);
        //});

        // Start recognition
        startButton.addEventListener('click', () => {
            if (!recognition) {
                initSpeechRecognition();
            }
            recognition.start();
            console.log('Speech recognition started');
        });

        // Stop recognition
        stopButton.addEventListener('click', () => {
            //if (recognition) {
                recognition.stop();
                console.log('Speech recognition stopped');
            //}
        });



        }


        // Append the transcript to the div with speaker prefix
        function appendTranscript(transcript) {
                if (transcript.length == 0) {
                    exit();
                }
            const speaker = isDoctorSpeaking ? 'Speaker: ' : 'Speaker: ';
            transcriptionDiv.innerHTML += `<p><strong>${speaker}</strong>${transcript}</p>`;
        }

        // Start speech recognition
        initSpeechRecognition();
    </script>




<script>
initSpeechRecognition();
</script>
</body>
</html>
